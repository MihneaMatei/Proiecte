{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b770ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyvirtualcam\n",
    "import socket\n",
    "import threading\n",
    "import queue\n",
    "from PIL import Image\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602da698",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy=cv2.imread('D:/ACS/mihnea/happy.png', cv2.IMREAD_UNCHANGED)\n",
    "angry=cv2.imread('D:/ACS/mihnea/angry.png', cv2.IMREAD_UNCHANGED)\n",
    "neutral=cv2.imread('D:/ACS/mihnea/neutral.png', cv2.IMREAD_UNCHANGED)\n",
    "surprise=cv2.imread('D:/ACS/mihnea/surprise.png', cv2.IMREAD_UNCHANGED)\n",
    "bored=cv2.imread('D:/ACS/mihnea/bored.png', cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ebe277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flag to control the streaming\n",
    "stop_streaming = threading.Event()\n",
    "\n",
    "# def start_streaming():\n",
    "#     og_background = Image.open('wp.jpg')\n",
    "#     width, height = 1280, 720  # Set the width and height of the virtual camera\n",
    "#     fps = 30  # Set the frame rate of the virtual camera\n",
    "#     with pyvirtualcam.Camera(width=width, height=height, fps=fps) as cam:\n",
    "#         # cât timp există conexiuni la server\n",
    "#         while not stop_streaming.is_set():\n",
    "#             background = og_background.copy()\n",
    "#             emotions = {}\n",
    "#             # dacă există informații în coadă, acestea sunt extrase\n",
    "#             if not emotion_queue.empty():\n",
    "#                 emotion_data = emotion_queue.get()\n",
    "#                 client_id, emotion = emotion_data\n",
    "#                 emotions[client_id] = emotion\n",
    "#             # avatarele și fundalul sunt actualizate în timp real, în funcție de informația primită\n",
    "#             # For example, assume there are two clients: \"client1\" and \"client2\"\n",
    "#             avatar1 = None\n",
    "#             avatar2 = None\n",
    "\n",
    "#             if \"test_id\" in emotions:\n",
    "#                 if emotions[\"test_id\"] == \"Happy\":\n",
    "#                     avatar1 = happy\n",
    "#                 elif emotions[\"test_id\"] == \"Angry\":\n",
    "#                     avatar1 = angry\n",
    "#                 elif emotions[\"test_id\"] == \"Bored\":\n",
    "#                     avatar1 = bored\n",
    "#                 elif emotions[\"test_id\"] == \"Neutral\":\n",
    "#                     avatar1 = neutral\n",
    "#                 elif emotions[\"test_id\"] == \"Surprise\":\n",
    "#                     avatar1 = surprise\n",
    "\n",
    "#             if \"client1\" in emotions:\n",
    "#                 if emotions[\"client1\"] == \"Happy\":\n",
    "#                     avatar2 = happy\n",
    "#                 elif emotions[\"client1\"] == \"Angry\":\n",
    "#                     avatar2 = angry\n",
    "#                 elif emotions[\"client1\"] == \"Bored\":\n",
    "#                     avatar2 = bored\n",
    "#                 elif emotions[\"client1\"] == \"Neutral\":\n",
    "#                     avatar2 = neutral\n",
    "#                 elif emotions[\"client1\"] == \"Surprise\":\n",
    "#                     avatar2 = surprise\n",
    "\n",
    "#             if avatar1 is not None and avatar1.any():\n",
    "#                 background_width, background_height = 1280, 720\n",
    "\n",
    "#                 # Resize and position the avatar on the background\n",
    "#                 avatar_image = Image.fromarray(avatar1)\n",
    "#                 resized_avatar = avatar_image.resize((180, 180))\n",
    "#                 avatar_width, avatar_height = resized_avatar.size\n",
    "\n",
    "#                 x = ((background_width - avatar_width) // 2) - 250  # Adjust the position for multiple avatars\n",
    "#                 y = ((background_height - avatar_height) // 2)\n",
    "\n",
    "#                 background.paste(resized_avatar, (x, y), resized_avatar)\n",
    "\n",
    "#             if avatar2 is not None and avatar2.any():\n",
    "#                 background_width, background_height = 1280, 720\n",
    "\n",
    "#                 # Resize and position the avatar on the background\n",
    "#                 avatar_image = Image.fromarray(avatar2)\n",
    "#                 resized_avatar = avatar_image.resize((180, 180))\n",
    "#                 avatar_width, avatar_height = resized_avatar.size\n",
    "\n",
    "#                 x = ((background_width - avatar_width) // 2) + 250  # Adjust the position for multiple avatars\n",
    "#                 y = (background_height - avatar_height) // 2\n",
    "\n",
    "#                 background.paste(resized_avatar, (x, y), resized_avatar)\n",
    "            \n",
    "#             # Convert the background image to a NumPy array and BGR color format\n",
    "#             frame = np.array(background.convert('RGB'))\n",
    "#             frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#             # Convert the frame to RGB format\n",
    "#             frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#             # Send the frame to the virtual camera\n",
    "#             cam.send(frame_rgb)\n",
    "#             cv2.imshow('Magic Stuff', frame_rgb)\n",
    "\n",
    "#             if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "\n",
    "#         # Wait for the emotion processing thread to finish\n",
    "#         emotion_thread.join()\n",
    "\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# def start_streaming():\n",
    "#     og_background = Image.open('wp.jpg')\n",
    "#     width, height = 1280, 720  # Set the width and height of the virtual camera\n",
    "#     fps = 30  # Set the frame rate of the virtual camera\n",
    "#     with pyvirtualcam.Camera(width=width, height=height, fps=fps) as cam:\n",
    "#         background = og_background.copy()\n",
    "#         avatars = {}  # Store the avatars for each client\n",
    "\n",
    "#         while not stop_streaming.is_set():\n",
    "#             emotions = {}\n",
    "#             if not emotion_queue.empty():\n",
    "#                 emotion_data = emotion_queue.get()\n",
    "#                 client_id, emotion = emotion_data\n",
    "#                 emotions[client_id] = emotion\n",
    "            \n",
    "#             # Update the avatars and background based on the received emotions\n",
    "#             for client_id, emotion in emotions.items():\n",
    "#                 if emotion == \"Happy\":\n",
    "#                     avatars[client_id] = happy\n",
    "#                 elif emotion == \"Angry\":\n",
    "#                     avatars[client_id] = angry\n",
    "#                 elif emotion == \"Bored\":\n",
    "#                     avatars[client_id] = bored\n",
    "#                 elif emotion == \"Neutral\":\n",
    "#                     avatars[client_id] = neutral\n",
    "#                 elif emotion == \"Surprise\":\n",
    "#                     avatars[client_id] = surprise\n",
    "#                 else:\n",
    "#                     avatars[client_id] = None\n",
    "\n",
    "#             # Clear the background\n",
    "#             background_width, background_height = 1280, 720\n",
    "            \n",
    "#             # Position the avatars on the background\n",
    "#             for i, (client_id, avatar) in enumerate(avatars.items()):\n",
    "#                 if avatar is not None and avatar.any():\n",
    "#                     # Resize and position the avatar on the background\n",
    "#                     avatar_image = Image.fromarray(avatar)\n",
    "#                     resized_avatar = avatar_image.resize((180, 180))\n",
    "#                     avatar_width, avatar_height = resized_avatar.size\n",
    "\n",
    "#                     x = ((background_width - avatar_width) // 2) - 250 + 500*i  # Adjust the position for multiple avatars\n",
    "#                     y = (background_height - avatar_height) // 2\n",
    "\n",
    "#                     background.paste(resized_avatar, (x, y), resized_avatar)\n",
    "\n",
    "#             # Convert the background image to a NumPy array and BGR color format\n",
    "#             frame = np.array(background.convert('RGB'))\n",
    "#             frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#             # Convert the frame to RGB format\n",
    "#             frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#             # Send the frame to the virtual camera\n",
    "#             cam.send(frame_rgb)\n",
    "#             cv2.imshow('Magic Stuff', frame_rgb)\n",
    "\n",
    "#             if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "#         emotion_thread.join()\n",
    "\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "def start_streaming():\n",
    "    og_background = Image.open('wp.jpg')\n",
    "    width, height = 1280, 720  # Set the width and height of the virtual camera\n",
    "    fps = 30  # Set the frame rate of the virtual camera\n",
    "    with pyvirtualcam.Camera(width=width, height=height, fps=fps) as cam:\n",
    "        background = og_background.copy()\n",
    "        avatars = {}  # Store the avatars for each client\n",
    "        prev_emotions = {}\n",
    "\n",
    "        while not stop_streaming.is_set():\n",
    "            emotions = {}\n",
    "            if not emotion_queue.empty():\n",
    "                emotion_data = emotion_queue.get()\n",
    "                client_id, emotion = emotion_data\n",
    "                emotions[client_id] = emotion\n",
    "\n",
    "            if emotions != prev_emotions:\n",
    "                background = og_background.copy()\n",
    "            \n",
    "            # Update the avatars and background based on the received emotions\n",
    "            for client_id, emotion in emotions.items():\n",
    "                if emotion == \"Happy\":\n",
    "                    avatars[client_id] = happy\n",
    "                elif emotion == \"Angry\":\n",
    "                    avatars[client_id] = angry\n",
    "                elif emotion == \"Bored\":\n",
    "                    avatars[client_id] = bored\n",
    "                elif emotion == \"Neutral\":\n",
    "                    avatars[client_id] = neutral\n",
    "                elif emotion == \"Surprise\":\n",
    "                    avatars[client_id] = surprise\n",
    "                else:\n",
    "                    avatars[client_id] = None\n",
    "\n",
    "            background_width, background_height = 1280, 720\n",
    "                    \n",
    "            # Position the avatars on the background\n",
    "            for i, (client_id, avatar) in enumerate(avatars.items()):\n",
    "                if avatar is not None and avatar.any():\n",
    "                    # Resize and position the avatar on the background\n",
    "                    avatar_image = Image.fromarray(avatar)\n",
    "                    resized_avatar = avatar_image.resize((180, 180))\n",
    "                    avatar_width, avatar_height = resized_avatar.size\n",
    "\n",
    "                    x = ((background_width - avatar_width) // 2) - 250 + 500*i  # Adjust the position for multiple avatars\n",
    "                    y = (background_height - avatar_height) // 2\n",
    "\n",
    "                    background.paste(resized_avatar, (x, y), resized_avatar)\n",
    "\n",
    "            # Convert the background image to a NumPy array and BGR color format\n",
    "            frame = np.array(background.convert('RGB'))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Convert the frame to RGB format\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Send the frame to the virtual camera\n",
    "            cam.send(frame_rgb)\n",
    "            cv2.imshow('Magic Stuff', frame_rgb)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        emotion_thread.join()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    prev_emotions = emotions.copy()\n",
    "\n",
    "\n",
    "streaming_thread = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec898d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_id: Conectarea de la ('192.168.56.1', 1901) a avut succes!\n",
      "client1: Conectarea de la ('192.168.56.1', 1900) a avut succes!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Conda\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\rayko\\AppData\\Local\\Temp\\ipykernel_11924\\2798998734.py\", line 12, in handle_client\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "# variabile globale pentru a stoca date despre client și coada de emoții\n",
    "clients_info = OrderedDict()\n",
    "emotion_queue = queue.Queue()\n",
    "\n",
    "# funcția destinată manevrării clienților\n",
    "def handle_client(client_socket, address, client_id):\n",
    "    global clients_info\n",
    "    print(f\"{client_id}: Conectarea de la {address} a avut succes!\")\n",
    "    client_socket.send(bytes(\"Welcome to the server!\", \"utf-8\"))\n",
    "    # buclă activă pe parcursul conexiunii\n",
    "    while True:\n",
    "        msg = client_socket.recv(64)\n",
    "        if not msg:\n",
    "            break\n",
    "        # informațiile despre sentimentul detectat sunt decodificate\n",
    "        emotion = msg.decode('utf-8')\n",
    "        # în informațiile despre client sunt adăugate emoțiile\n",
    "        clients_info[client_id] = emotion\n",
    "        # informația despre emoție este adăugată în coadă\n",
    "        emotion_queue.put((client_id, emotion))\n",
    "    # la încetarea conexiunii, firul este închis și datele despre client șterse\n",
    "    del clients_info[client_id]  # Remove the client when it disconnects\n",
    "    client_socket.close()\n",
    "\n",
    "def start_server():\n",
    "    global streaming_thread\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind((socket.gethostname(), 1234))\n",
    "    server_socket.listen(5)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            client_socket, address = server_socket.accept()\n",
    "            msg = client_socket.recv(64)\n",
    "            client_id = msg.decode('utf-8')  # Client sends its ID first\n",
    "            thread = threading.Thread(target=handle_client, args=(client_socket, address, client_id))\n",
    "            thread.start()\n",
    "            #print(len(clients_info))\n",
    "            if len(clients_info) >= 0 and not streaming_thread:\n",
    "                # Start streaming\n",
    "                stop_streaming.clear()  # Reset the stop flag\n",
    "                streaming_thread = threading.Thread(target=start_streaming)\n",
    "                streaming_thread.start()\n",
    "            elif len(clients_info) == -1 and streaming_thread:\n",
    "                # Stop streaming\n",
    "                stop_streaming.set()\n",
    "                streaming_thread.join()  # Wait for the streaming thread to finish\n",
    "                streaming_thread = None\n",
    "\n",
    "    finally:\n",
    "        server_socket.close()\n",
    "\n",
    "\n",
    "start_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed6828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa7c21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
